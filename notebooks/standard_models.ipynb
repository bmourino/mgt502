{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/beatriz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = list(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"/home/beatriz/Documents/courses/mgt502/project/mgt502/outputs/plots/\"\n",
    "data = pd.read_csv(os.path.abspath(\"../available_datasets/training_data.csv\"))\n",
    "\n",
    "X = data['sentence']\n",
    "y = data['difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beatriz/miniconda3/envs/mgt502/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, TFFlaubertModel\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaubert/flaubert_base_cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m TFFlaubertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaubert/flaubert_base_cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFFlaubertModel\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
    "\n",
    "model = TFFlaubertModel.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "\n",
    "outputs = model(inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beatriz/miniconda3/envs/mgt502/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/beatriz/miniconda3/envs/mgt502/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 1}\n",
      "Confusion matrix for Logistic Regression:\n",
      "Predicted   A1  A2  B1  B2  C1  C2\n",
      "Actual                            \n",
      "A1         110  39   8   6   3   0\n",
      "A2          50  61  33   5   5   4\n",
      "B1          28  52  59   8   6  13\n",
      "B2           9   6  14  69  29  26\n",
      "C1           5  12  13  22  66  34\n",
      "C2           5   5  14  19  30  92\n",
      "Evaluation metrics for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.53      0.66      0.59       166\n",
      "          A2       0.35      0.39      0.37       158\n",
      "          B1       0.42      0.36      0.38       166\n",
      "          B2       0.53      0.45      0.49       153\n",
      "          C1       0.47      0.43      0.45       152\n",
      "          C2       0.54      0.56      0.55       165\n",
      "\n",
      "    accuracy                           0.48       960\n",
      "   macro avg       0.48      0.47      0.47       960\n",
      "weighted avg       0.48      0.48      0.47       960\n",
      "\n",
      "Best parameters for KNN: {'n_neighbors': 3}\n",
      "Confusion matrix for KNN:\n",
      "Predicted   A1  A2  B1  B2  C1  C2\n",
      "Actual                            \n",
      "A1         152  11   1   2   0   0\n",
      "A2         148   9   1   0   0   0\n",
      "B1         144  15   5   2   0   0\n",
      "B2         141   8   0   3   1   0\n",
      "C1         144   3   2   0   3   0\n",
      "C2         161   1   0   0   2   1\n",
      "Evaluation metrics for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.17      0.92      0.29       166\n",
      "          A2       0.19      0.06      0.09       158\n",
      "          B1       0.56      0.03      0.06       166\n",
      "          B2       0.43      0.02      0.04       153\n",
      "          C1       0.50      0.02      0.04       152\n",
      "          C2       1.00      0.01      0.01       165\n",
      "\n",
      "    accuracy                           0.18       960\n",
      "   macro avg       0.47      0.17      0.09       960\n",
      "weighted avg       0.48      0.18      0.09       960\n",
      "\n",
      "Best parameters for Decision Tree: {'max_depth': 20}\n",
      "Confusion matrix for Decision Tree:\n",
      "Predicted   A1  A2  B1  B2  C1  C2\n",
      "Actual                            \n",
      "A1         100  29  12  15   2   8\n",
      "A2          71  31  28  21   1   6\n",
      "B1          51  38  29  25  12  11\n",
      "B2          23  10  18  63  20  19\n",
      "C1          18  10  19  55  26  24\n",
      "C2          26  16  15  59  19  30\n",
      "Evaluation metrics for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.35      0.60      0.44       166\n",
      "          A2       0.23      0.20      0.21       158\n",
      "          B1       0.24      0.17      0.20       166\n",
      "          B2       0.26      0.41      0.32       153\n",
      "          C1       0.33      0.17      0.22       152\n",
      "          C2       0.31      0.18      0.23       165\n",
      "\n",
      "    accuracy                           0.29       960\n",
      "   macro avg       0.29      0.29      0.27       960\n",
      "weighted avg       0.29      0.29      0.27       960\n",
      "\n",
      "Best parameters for Random Forest: {'n_estimators': 500}\n",
      "Confusion matrix for Random Forest:\n",
      "Predicted   A1  A2  B1  B2  C1  C2\n",
      "Actual                            \n",
      "A1         139  15   7   4   1   0\n",
      "A2          82  43  21   9   0   3\n",
      "B1          53  45  44  10   7   7\n",
      "B2          24  16  16  49  30  18\n",
      "C1          17   7  17  36  51  24\n",
      "C2          17  12  13  28  38  57\n",
      "Evaluation metrics for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A1       0.42      0.84      0.56       166\n",
      "          A2       0.31      0.27      0.29       158\n",
      "          B1       0.37      0.27      0.31       166\n",
      "          B2       0.36      0.32      0.34       153\n",
      "          C1       0.40      0.34      0.37       152\n",
      "          C2       0.52      0.35      0.42       165\n",
      "\n",
      "    accuracy                           0.40       960\n",
      "   macro avg       0.40      0.40      0.38       960\n",
      "weighted avg       0.40      0.40      0.38       960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='sag'),# (solver='sag'),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"Logistic Regression\": {'C': [0.1, 1, 5, 10, 15, 20]},\n",
    "    \"KNN\": {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17]},\n",
    "    \"Decision Tree\": {'max_depth': [2, 4, 6, 10, 15, 20]},\n",
    "    \"Random Forest\": {'n_estimators': [10, 50, 100, 200, 500]}\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer() # stop_words=stop_words)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train_scale = scaler.fit_transform(X_train_vec)\n",
    "X_test_scale = scaler.transform(X_test_vec)\n",
    "\n",
    "X_train_df_tfidf = pd.DataFrame(X_train_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_test_df_tfidf = pd.DataFrame(X_test_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "eval_dict = {'model': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "best_parameters = {'model': [], 'best_parameters': []}\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train_scale, y_train)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    model = grid_search.best_estimator_\n",
    "    model.fit(X_train_scale, y_train)\n",
    "    y_pred = model.predict(X_test_scale)\n",
    "\n",
    "    # show confusion matrix and plot it\n",
    "    print(f\"Confusion matrix for {name}:\")\n",
    "    print(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']))\n",
    "    # plot confusion matrix\n",
    "    plt.figure()\n",
    "    plt.matshow(pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted']), cmap='Blues')\n",
    "    plt.title(name)\n",
    "    plt.savefig(output_folder+name+\".pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    print(f\"Evaluation metrics for {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    eval_dict['model'].append(name)\n",
    "    eval_dict['accuracy'].append(model.score(X_test_scale, y_test))\n",
    "    eval_dict['precision'].append(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['precision'])\n",
    "    eval_dict['recall'].append(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['recall'])\n",
    "    eval_dict['f1'].append(classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score'])\n",
    "    best_parameters['model'].append(name)\n",
    "    best_parameters['best_parameters'].append(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.476042</td>\n",
       "      <td>0.180208</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>0.398958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.475604</td>\n",
       "      <td>0.476458</td>\n",
       "      <td>0.285611</td>\n",
       "      <td>0.399041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.476042</td>\n",
       "      <td>0.180208</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>0.398958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.473248</td>\n",
       "      <td>0.088171</td>\n",
       "      <td>0.271956</td>\n",
       "      <td>0.381365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Logistic Regression       KNN Decision Tree Random Forest\n",
       "accuracy             0.476042  0.180208      0.290625      0.398958\n",
       "precision            0.475604  0.476458      0.285611      0.399041\n",
       "recall               0.476042  0.180208      0.290625      0.398958\n",
       "f1                   0.473248  0.088171      0.271956      0.381365"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude the model column\n",
    "df_eval = pd.DataFrame(eval_dict, index=eval_dict['model'])\n",
    "df_eval = df_eval.T\n",
    "# remove model row\n",
    "df_eval = df_eval.drop('model')\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = data['sentence']\n",
    "y_train_all = data['difficulty']\n",
    "\n",
    "vectorizer = TfidfVectorizer() # stop_words=stop_words)\n",
    "X_train_all_vec = vectorizer.fit_transform(X_train_all)\n",
    "\n",
    "model = LogisticRegression(C=1, max_iter=1000, solver='sag')\n",
    "model.fit(X_train_all_vec, y_train_all)\n",
    "\n",
    "# predict on unlabelled data \n",
    "data_unlabelled = pd.read_csv(os.path.abspath(\"../available_datasets/unlabelled_test_data.csv\"))\n",
    "X_unlabelled = data_unlabelled['sentence']\n",
    "\n",
    "X_unlabelled_vec = vectorizer.transform(X_unlabelled)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_unlabelled_scale = scaler.fit_transform(X_unlabelled_vec)\n",
    "\n",
    "X_unlabelled_df_tfidf = pd.DataFrame(X_unlabelled_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "y_unlabelled_pred = model.predict(X_unlabelled_scale)\n",
    "\n",
    "# create a new dataset with id from data_unlabelled and predicted difficulty. the dataset should have the columns \"id\" and \"difficulty\"\n",
    "data_unlabelled['difficulty'] = y_unlabelled_pred\n",
    "data_unlabelled_submit = data_unlabelled[['id', 'difficulty']]\n",
    "data_unlabelled_submit.to_csv(os.path.abspath(\"../outputs/datasets/predicted_logistic_regression.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = data['sentence']\n",
    "y_train_all = data['difficulty']\n",
    "\n",
    "vectorizer = TfidfVectorizer() # stop_words=stop_words)\n",
    "X_train_all_vec = vectorizer.fit_transform(X_train_all)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train_all_vec, y_train_all)\n",
    "\n",
    "# predict on unlabelled data \n",
    "data_unlabelled = pd.read_csv(os.path.abspath(\"../available_datasets/unlabelled_test_data.csv\"))\n",
    "X_unlabelled = data_unlabelled['sentence']\n",
    "\n",
    "X_unlabelled_vec = vectorizer.transform(X_unlabelled)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_unlabelled_scale = scaler.fit_transform(X_unlabelled_vec)\n",
    "\n",
    "X_unlabelled_df_tfidf = pd.DataFrame(X_unlabelled_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "y_unlabelled_pred = model.predict(X_unlabelled_scale)\n",
    "\n",
    "# create a new dataset with id from data_unlabelled and predicted difficulty. the dataset should have the columns \"id\" and \"difficulty\"\n",
    "data_unlabelled['difficulty'] = y_unlabelled_pred\n",
    "data_unlabelled_submit = data_unlabelled[['id', 'difficulty']]\n",
    "data_unlabelled_submit.to_csv(os.path.abspath(\"../outputs/datasets/predicted_knn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = data['sentence']\n",
    "y_train_all = data['difficulty']\n",
    "\n",
    "vectorizer = TfidfVectorizer() # stop_words=stop_words)\n",
    "X_train_all_vec = vectorizer.fit_transform(X_train_all)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=10)\n",
    "model.fit(X_train_all_vec, y_train_all)\n",
    "\n",
    "# predict on unlabelled data \n",
    "data_unlabelled = pd.read_csv(os.path.abspath(\"../available_datasets/unlabelled_test_data.csv\"))\n",
    "X_unlabelled = data_unlabelled['sentence']\n",
    "\n",
    "X_unlabelled_vec = vectorizer.transform(X_unlabelled)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_unlabelled_scale = scaler.fit_transform(X_unlabelled_vec)\n",
    "\n",
    "X_unlabelled_df_tfidf = pd.DataFrame(X_unlabelled_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "y_unlabelled_pred = model.predict(X_unlabelled_scale)\n",
    "\n",
    "# create a new dataset with id from data_unlabelled and predicted difficulty. the dataset should have the columns \"id\" and \"difficulty\"\n",
    "data_unlabelled['difficulty'] = y_unlabelled_pred\n",
    "data_unlabelled_submit = data_unlabelled[['id', 'difficulty']]\n",
    "data_unlabelled_submit.to_csv(os.path.abspath(\"../outputs/datasets/predicted_tree.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = data['sentence']\n",
    "y_train_all = data['difficulty']\n",
    "\n",
    "vectorizer = TfidfVectorizer() # stop_words=stop_words)\n",
    "X_train_all_vec = vectorizer.fit_transform(X_train_all)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500)    \n",
    "model.fit(X_train_all_vec, y_train_all)\n",
    "\n",
    "# predict on unlabelled data \n",
    "data_unlabelled = pd.read_csv(os.path.abspath(\"../available_datasets/unlabelled_test_data.csv\"))\n",
    "X_unlabelled = data_unlabelled['sentence']\n",
    "\n",
    "X_unlabelled_vec = vectorizer.transform(X_unlabelled)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_unlabelled_scale = scaler.fit_transform(X_unlabelled_vec)\n",
    "\n",
    "X_unlabelled_df_tfidf = pd.DataFrame(X_unlabelled_scale.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "y_unlabelled_pred = model.predict(X_unlabelled_scale)\n",
    "\n",
    "# create a new dataset with id from data_unlabelled and predicted difficulty. the dataset should have the columns \"id\" and \"difficulty\"\n",
    "data_unlabelled['difficulty'] = y_unlabelled_pred\n",
    "data_unlabelled_submit = data_unlabelled[['id', 'difficulty']]\n",
    "data_unlabelled_submit.to_csv(os.path.abspath(\"../outputs/datasets/predicted_forest.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgt502",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
